{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Gaussian example\n",
    "\n",
    "As an introductory example we can use astroABC to find the posterior distribution for some Gaussian distributed data. Although in this case we already know the likelihood this example is to illustrate how to call astroABC and provide user-defined metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by importing astroabc and numpy\n",
    "import numpy as np\n",
    "import astroabc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to provide:\n",
    "\n",
    "- a dataset\n",
    "- a forwards simulating model for the data\n",
    "- a method defining the distance metric.\n",
    "\n",
    "For this example we generate a dataset of a 1000 draws from a 2D multi-Gaussian where the true means are e.g\n",
    "\n",
    "$\\mu_{1,true} = 0.037579, \\, \\mu_{2, true}=0.573537$\n",
    "\n",
    "and we have fixed the covariance matrix to be  a diagonal matrix with $\\sigma_1^2 = \\sigma_2^2 = 0.05$. \n",
    "We can do this using an inbuilt model class in astroabc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the fake data with diagonal covariance\n",
    "means= np.array([0.037579, 0.573537])\n",
    "cov =np.array([0.01,0.005,0.005,0.1])\n",
    "data = astroabc.Model(\"normal\",1000).make_mock(means,cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the make_mock method also provides a forwards simulating model for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a method for simulating the data given input parameters\n",
    "def simulation(param, pool=None):\n",
    "    cov =np.array([0.01,0.005,0.005,0.1])\n",
    "    #Ideally do something with the pool here\n",
    "    return astroabc.Model(\"normal\",10000).make_mock(param,cov)\n",
    "\n",
    "model_sim = simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a distance metric method. In this example instead of using all of the data (all 1000 draws from a 2D Gaussian) we use the means of the data as a summary statistic and our distance metric is the sum over the difference in the means for the 2D Gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_metric(d,x):\n",
    "    return np.sum(np.abs(np.mean(x,axis=0) - np.mean(d,axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we specify priors for each of the parameters we want to vary in the sampler. This is done by specifying a list of tuples. The zeroth element in each tuple should be a string specifying the prior for this parameter and the first element should be a list of the hyperparameters needed for this prior.\n",
    "e.g. below we use a normal distribution with mean  0 and variance 0.5 for the first parameter and a uniform distribution from 0.1 - 0.9 for the second parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors =  [('normal', [0.03,0.1]), ('uniform', [0.1, 0.9])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set some keywords for astroABC. This can be done by creating a dictionary of inputs which are passed to the sampler. Many of these entries have defaults and do not need to be specified explicitly.\n",
    "Only the name of the distance metric method needs to be explicity provided as a keyword.\n",
    "The full set of keywords are given in the doc string of the class. Some examples are\n",
    "\n",
    "- tol_type: which specifies the decreasing tolerance levels. \"exp\",\"lin\", \"log\" and \"const\" are options. (default = 'exp')\n",
    "\n",
    "- verbose: level of verbosity, 0 = no printout to screen, 1 = print to screen  (default = 0)\n",
    "\n",
    "- adapt_t: Boolean True/False for adaptive threshold setting (default = False)\n",
    "\n",
    "- threshold: qth quantile used in adaptive threshold setting (default = 75)\n",
    "\n",
    "- pert_kernel: 1 =component wise pert. with local diag variance; 2 = multivariate pert. based on local covariance\n",
    "\n",
    "- variance_method: 0 =weighted covariance, 1= Filippi, 2 = TVZ, 3= Leodoit_Wolf, 4=k-nn (default = 0)\n",
    "\n",
    "- dfunc:method for calculating the distance metric\n",
    "\n",
    "- from_restart: Boolean True/False\n",
    "\n",
    "- restart: string name of restart file\n",
    "\n",
    "- outfile:string specifying name of output file (default = abc_out.txt)\n",
    "\n",
    "- mpi: Boolean True/False (default = False)\n",
    "\n",
    "- mp:Boolean True/False (default = False)\n",
    "\n",
    "- num_proc:number of threads for mp setting (default = None)\n",
    "\n",
    "Please see the doc strings of the astroABC sampler for details on each of these settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop={'dfunc':dist_metric, 'outfile':\"gaussian_example.txt\", 'verbose':1, 'adapt_t': True, 'pert_kernel':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create an instance of our sampler. \n",
    "To do this we just need to specify the following to the astroabc.ABC_class\n",
    "\n",
    "astroabc.ABC_class(number of parameters,number of particles,data,tolerance levels,number of iterations,priors,prop)\n",
    "\n",
    "To begin let's run in serial using 100 particles for 30 iterations with default tolerance levels of a maximum threshold of 0.7 and  a minimum threshold of 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t\n",
      "\t ########################     astroABC     ########################\t\n",
      "\t \t\n",
      "\t Npart=100 \t numt=20 \t tol=[0.5000,0.0020] exp\n",
      "\t Priors= [('normal', [0.03, 0.1]), ('uniform', [0.1, 0.9])]\n"
     ]
    }
   ],
   "source": [
    "sampler = astroabc.ABC_class(2,100,data,[0.5,0.002],20,priors,**prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we simply begin sampling on our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Step: 0 \t tol: 0.5 \t Params: [0.004831022751718228, 0.5316987441872384]\n",
      "\t Step: 1 \t tol: 0.3674356729086831 \t Params: [0.02321074264082056, 0.5742511100054313]\n",
      "\t Step: 2 \t tol: 0.30166515686162976 \t Params: [0.036441292743712723, 0.5849798902653633]\n",
      "\t Step: 3 \t tol: 0.2339575792400317 \t Params: [0.04721763109698714, 0.5835376098791599]\n",
      "\t Step: 4 \t tol: 0.19340880389783577 \t Params: [0.043681453658168924, 0.5825229124687235]\n",
      "\t Step: 5 \t tol: 0.1698794471891293 \t Params: [0.025025449631187073, 0.5864426900677008]\n",
      "\t Step: 6 \t tol: 0.1447905652346464 \t Params: [0.03934585197338663, 0.5838000248009465]\n",
      "\t Step: 7 \t tol: 0.1243271216418435 \t Params: [0.04108654251443204, 0.5850115948283879]\n",
      "\t Step: 8 \t tol: 0.10398803512341327 \t Params: [0.03269305321900622, 0.5840846504880716]\n",
      "\t Step: 9 \t tol: 0.08868583214998207 \t Params: [0.03250952497115013, 0.5855360667857193]\n",
      "\t Step: 10 \t tol: 0.0756948315479395 \t Params: [0.035796696950396154, 0.580821486914087]\n",
      "\t Step: 11 \t tol: 0.06511416184901217 \t Params: [0.03984439373095, 0.5839234813748221]\n",
      "\t Step: 12 \t tol: 0.05343054662205011 \t Params: [0.03617377326621689, 0.5849199639229566]\n",
      "\t Step: 13 \t tol: 0.04621903048072745 \t Params: [0.037625099407746984, 0.5880483203398328]\n",
      "\t Step: 14 \t tol: 0.037262989801758156 \t Params: [0.038806559919571944, 0.5851600667183121]\n",
      "\t Step: 15 \t tol: 0.031602756631985564 \t Params: [0.03701197479380795, 0.5831796705165299]\n",
      "\t Step: 16 \t tol: 0.026952790181097103 \t Params: [0.037998247499682836, 0.5832717144071579]\n",
      "\t Step: 17 \t tol: 0.023255214366412626 \t Params: [0.038519266122226475, 0.5825269763266807]\n",
      "\t Step: 18 \t tol: 0.019505198348594738 \t Params: [0.039200951041888976, 0.5838628870292696]\n",
      "\t Step: 19 \t tol: 0.01637099476629593 \t Params: [0.038146724068983597, 0.5849711692529307]\n"
     ]
    }
   ],
   "source": [
    "sampler.sample(model_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The output above shows the estimated means of the 2D Gaussian averaged over all 100 particles at each iteration, together with the tolerance level. Note above that the sampling may end before 20 iterations if the minimum tolerance level is reached first.\n",
    "Recall that the true parameter values are $\\mu_{1,true} = 0.037579, \\, \\mu_{2, true}=0.573537$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours estimation for data sample with covariance matrix\n",
    "\n",
    "We could also have created a dataset with a full covariance matrix using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "means= np.array([0.7579, 0.273537])\n",
    "cov = np.array([0.1,0.01,0.01,0.1])\n",
    "data_cov = Model(\"normal\",1000).make_mock(means,cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping model simulation and distance methods the same as above. We can select a different way of estimating the covariance amongst all the particles using k-nearest neighbours. This returns a local covariance estimate and in many cases this reaches convergence faster then using a weighted covariance amongst all particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors =  [('uniform', [0.1,0.9]), ('uniform', [0.1, 0.9])]\n",
    "prop={'dfunc':dist_metric, 'outfile':\"gaussian_example.txt\", 'verbose':1, \\\n",
    "      'adapt_t': True, 'variance_method':4, 'k_near':10 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t\n",
      "\t ########################     astroABC     ########################\t\n",
      "\t \t\n",
      "\t Npart=100 \t numt=25 \t tol=[0.5000,0.0020] exp\n",
      "\t Priors= [('uniform', [0.1, 0.9]), ('uniform', [0.1, 0.9])]\n"
     ]
    }
   ],
   "source": [
    "sampler = ABC_class(2,100,data_cov,[0.5,0.002],25,priors,**prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Step: 0 \t tol: 0.5 \t Params: [0.6417417888667538, 0.3769805241152575]\n",
      "\t Step: 1 \t tol: 0.43598082896982815 \t Params: [0.6728761879909225, 0.3626886691562053]\n",
      "\t Step: 2 \t tol: 0.358520432619466 \t Params: [0.7227864485788014, 0.31132619316770155]\n",
      "\t Step: 3 \t tol: 0.2833997638790343 \t Params: [0.7440094967360175, 0.2987062443319014]\n",
      "\t Step: 4 \t tol: 0.21592705669630358 \t Params: [0.7578314852638425, 0.28997038404805464]\n",
      "\t Step: 5 \t tol: 0.1832059820435786 \t Params: [0.7725999199112689, 0.2711524459774648]\n",
      "\t Step: 6 \t tol: 0.1563979221312114 \t Params: [0.7549734561659688, 0.280156875829783]\n",
      "\t Step: 7 \t tol: 0.12951796909825125 \t Params: [0.7561589203189962, 0.28703131841749463]\n",
      "\t Step: 8 \t tol: 0.1093959516000065 \t Params: [0.7646331246580728, 0.2767507341644505]\n",
      "\t Step: 9 \t tol: 0.08927254752993467 \t Params: [0.7631681442434737, 0.2820566810999924]\n",
      "\t Step: 10 \t tol: 0.07633646127328605 \t Params: [0.7584185873502948, 0.2795299299446455]\n",
      "\t Step: 11 \t tol: 0.061068540755597894 \t Params: [0.752618957552296, 0.27880575189303963]\n",
      "\t Step: 12 \t tol: 0.05061479870880048 \t Params: [0.7569674388914795, 0.2742962959261214]\n",
      "\t Step: 13 \t tol: 0.04088574143743237 \t Params: [0.7574683792627619, 0.2777022756484693]\n",
      "\t Step: 14 \t tol: 0.03449755151429326 \t Params: [0.7602516050532038, 0.27900294921886354]\n",
      "\t Step: 15 \t tol: 0.028311973885197322 \t Params: [0.7594578199160145, 0.2814250761815206]\n",
      "\t Step: 16 \t tol: 0.024854485949822425 \t Params: [0.758612139644833, 0.28191228349811726]\n",
      "\t Step: 17 \t tol: 0.02080047547436792 \t Params: [0.7580105537118261, 0.28091831607808415]\n",
      "\t Step: 18 \t tol: 0.018123121350981278 \t Params: [0.759419825029535, 0.2812787295688279]\n",
      "\t Step: 19 \t tol: 0.01488107118582739 \t Params: [0.7593977382315026, 0.2808831912135362]\n",
      "\t Step: 20 \t tol: 0.012772810365051915 \t Params: [0.7588644879425643, 0.2804332292642587]\n",
      "\t Step: 21 \t tol: 0.01054868328411554 \t Params: [0.7592091183480909, 0.2806129347880487]\n",
      "\t Step: 22 \t tol: 0.008556361908366159 \t Params: [0.7589018644937893, 0.28085938213260714]\n",
      "\t Step: 23 \t tol: 0.0070204547318383215 \t Params: [0.7590723043195702, 0.2809934891621416]\n",
      "\t Step: 24 \t tol: 0.006059962305213662 \t Params: [0.7590556114343996, 0.2802493203704434]\n"
     ]
    }
   ],
   "source": [
    "sampler.sample(model_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
